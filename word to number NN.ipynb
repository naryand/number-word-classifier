{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding, Flatten, Reshape\n",
    "high = 100000000\n",
    "digits = 12 #len(str(high))\n",
    "pad = 12\n",
    "\n",
    "from num2words import num2words\n",
    "import random\n",
    "\n",
    "def index_list(pos):\n",
    "    index_list = [0] * (pos)\n",
    "    index_list.append(1)\n",
    "    index_list += [0] * (10-pos-1)\n",
    "    return index_list\n",
    "\n",
    "def create_data(low, high, num):\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for i in range(num):\n",
    "        a = random.randrange(low, high)\n",
    "        b = a\n",
    "        words = num2words(b)\n",
    "        c = str(b).zfill(digits)  \n",
    "        x_data.append(words.replace(\"-\", \" \").replace(\",\", \"\").replace(\" and \",\" \"))\n",
    "        num_list = []\n",
    "        for i in range(digits):\n",
    "            num_list.append(index_list(int(c[i])))\n",
    "        y_data.append(num_list)\n",
    "    return x_data, np.array(y_data)\n",
    "\n",
    "# appends some data to dataset\n",
    "def append_data(x, y, x_data, y_data):\n",
    "    x_data.append(x.replace(\"-\", \" \").replace(\",\", \"\").replace(\" and \",\" \"))\n",
    "    c = str(y).zfill(digits) \n",
    "    num_list = [[]]\n",
    "    for i in range(digits):\n",
    "        num_list[0].append(index_list(int(c[i])))\n",
    "    num_list = np.array(num_list)\n",
    "    y_data = np.concatenate((y_data, num_list), axis=0)\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train = create_data(0, high, 600000)\n",
    "x_test, y_test = create_data(0, high, 400000)\n",
    "\n",
    "# change some \"one thousand six hundred\" to \"sixteen hundred\" etc.\n",
    "for i in range(10):\n",
    "    for j in range(1000, 1500, 100):\n",
    "        x_train, y_train = append_data(num2words(j//100) + \" hundred\", j, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fifty eight million eight hundred thousand two hundred fifty two\n",
      "[ 0  0 14  6  3  6  1  2 12  1 14 12]\n",
      "[[1 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "num_words = 0\n",
    "for i in x_train:\n",
    "    num_words += len(i.split(\" \"))\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_train = np.array([[0]*(pad-len(i)) + i for i in x_train])\n",
    "\n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "x_test = np.array([[0]*(pad-len(i)) + i for i in x_test])\n",
    "\n",
    "print(tokenizer.sequences_to_texts(x_train)[342])\n",
    "print(x_train[342])\n",
    "print(y_train[342])\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 12, 12)            372       \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 120)               17400     \n",
      "_________________________________________________________________\n",
      "reshape_9 (Reshape)          (None, 12, 10)            0         \n",
      "=================================================================\n",
      "Total params: 17,772\n",
      "Trainable params: 17,772\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "600050/600050 [==============================] - 23s 38us/sample - loss: 0.1024 - acc: 0.9775\n",
      "Epoch 2/3\n",
      "600050/600050 [==============================] - 23s 38us/sample - loss: 0.0226 - acc: 0.9953\n",
      "Epoch 3/3\n",
      "600050/600050 [==============================] - 23s 39us/sample - loss: 0.0196 - acc: 0.9957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26a1c20d6d8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(Embedding(vocab_size, pad, input_length=pad))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(digits*10, activation=tf.nn.softmax))\n",
    "model.add(Reshape((digits,10)))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.fit(x_train, y_train, epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000/400000 [==============================] - 8s 20us/sample - loss: 0.0191 - acc: 0.9958\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "model.save('count2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('count2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40012\n",
      "40013\n",
      "123\n",
      "472222\n",
      "237140\n",
      "40000\n",
      "42200113\n"
     ]
    }
   ],
   "source": [
    "x = tokenizer.texts_to_sequences([\"twelve\"\n",
    "                                 ,\"thirteen\"\n",
    "                                 ,\"one hundred twenty three\"\n",
    "                                 ,\"four hundred seventy two thousand two hundred twenty two\"\n",
    "                                 ,\"two hundred thirty seven thousand one hundred forty\"\n",
    "                                 ,\"spongebob\"\n",
    "                                 ,\"forty two million two hundred thousand one hundred thirteen\"])\n",
    "x = np.array([[0]*(pad-len(i)) + i for i in x])\n",
    "predictions = new_model.predict(np.array(x))\n",
    "\n",
    "for prediction in predictions:\n",
    "    num = \"\"\n",
    "    for i in prediction:\n",
    "        num += str(i.argmax())\n",
    "    print(int(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
